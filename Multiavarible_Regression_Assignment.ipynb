{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quachtumy/SIC-2025/blob/main/Multiavarible_Regression_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpbHzUf8ca8"
      },
      "source": [
        "1. Viết câu lệnh đọc file Adv.cs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odKRRDzM8jTo",
        "outputId": "0c5305ab-8755-48fe-fee1-cc1a19c061e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wdT8FQ-I8vx-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DS 321 - Machine Learning 1/resources/Adv.csv', header=None)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kYNhYnyc85Dn",
        "outputId": "ea5b7260-5b21-4d08-d405-847034196d9d"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2     3\n",
              "0   230.1  37.8  69.2  22.1\n",
              "1    44.5  39.3  45.1  10.4\n",
              "2    17.2  45.9  69.3   9.3\n",
              "3   151.5  41.3  58.5  18.5\n",
              "4   180.8  10.8  58.4  12.9\n",
              "..    ...   ...   ...   ...\n",
              "95  163.3  31.6  52.9  16.9\n",
              "96  197.6   3.5   5.9  11.7\n",
              "97  184.9  21.0  22.0  15.5\n",
              "98  289.7  42.3  51.2  25.4\n",
              "99  135.2  41.7  45.9  17.2\n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0105d2b7-f91d-4fa1-9214-03901c87b1f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>163.3</td>\n",
              "      <td>31.6</td>\n",
              "      <td>52.9</td>\n",
              "      <td>16.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>197.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.9</td>\n",
              "      <td>11.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>184.9</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>15.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>289.7</td>\n",
              "      <td>42.3</td>\n",
              "      <td>51.2</td>\n",
              "      <td>25.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>135.2</td>\n",
              "      <td>41.7</td>\n",
              "      <td>45.9</td>\n",
              "      <td>17.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0105d2b7-f91d-4fa1-9214-03901c87b1f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0105d2b7-f91d-4fa1-9214-03901c87b1f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0105d2b7-f91d-4fa1-9214-03901c87b1f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49c7c5f6-5d00-45cb-9909-babdca3e526a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49c7c5f6-5d00-45cb-9909-babdca3e526a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49c7c5f6-5d00-45cb-9909-babdca3e526a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6d042df3-fd77-433a-b1ca-f1263cd659e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d042df3-fd77-433a-b1ca-f1263cd659e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170.76880784359668,\n        \"min\": 5.4,\n        \"max\": 1214.7,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          239.3,\n          202.5,\n          197.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.491621368880361,\n        \"min\": 1.4,\n        \"max\": 49.6,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          22.3,\n          15.9,\n          19.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.886047951822988,\n        \"min\": 0.3,\n        \"max\": 114.0,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          26.4,\n          26.2,\n          37.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.1368279132263135,\n        \"min\": 4.8,\n        \"max\": 25.4,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          9.6,\n          22.1,\n          15.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLH_nKh48cbB"
      },
      "source": [
        "2. Tách dữ liệu thành hai tập X và y. Trong đó y là cột cuối, X gồm các cột còn lại"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "X[:5], y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5av8mQU9PKv",
        "outputId": "e222f6d6-bb80-4177-f940-865972e583ea"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[230.1,  37.8,  69.2],\n",
              "        [ 44.5,  39.3,  45.1],\n",
              "        [ 17.2,  45.9,  69.3],\n",
              "        [151.5,  41.3,  58.5],\n",
              "        [180.8,  10.8,  58.4]]),\n",
              " array([22.1, 10.4,  9.3, 18.5, 12.9]))"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODY8h1r58cbC"
      },
      "source": [
        "3. Nối cột số 1 vào đầu tập X."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([np.ones([X.shape[0],1]), X])\n",
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fmlEh6r9x6O",
        "outputId": "1e9ef1bd-3092-449b-ddd9-f0fcdf4fa318"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1. , 230.1,  37.8,  69.2],\n",
              "       [  1. ,  44.5,  39.3,  45.1],\n",
              "       [  1. ,  17.2,  45.9,  69.3],\n",
              "       [  1. , 151.5,  41.3,  58.5],\n",
              "       [  1. , 180.8,  10.8,  58.4]])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VGg4PGN8cbC"
      },
      "source": [
        "4. Đưa dữ liệu về 0 đến 1 bằng cách chia cho giá trị lớn nhất tại mỗi cột"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X/np.max(X, axis=0)\n",
        "y = y/max(y)\n",
        "X[:5], y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRPNcNTQ_VZ2",
        "outputId": "b8741541-240c-4e9e-ccc1-3a2367fd717e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.        , 0.18942949, 0.76209677, 0.60701754],\n",
              "        [1.        , 0.03663456, 0.79233871, 0.39561404],\n",
              "        [1.        , 0.01415987, 0.92540323, 0.60789474],\n",
              "        [1.        , 0.12472215, 0.83266129, 0.51315789],\n",
              "        [1.        , 0.14884334, 0.21774194, 0.5122807 ]]),\n",
              " array([0.87007874, 0.40944882, 0.36614173, 0.72834646, 0.50787402]))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgI1PpYc8cbD"
      },
      "source": [
        "5. Viết hàm dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, m):\n",
        "  return np.dot(X, m)"
      ],
      "metadata": {
        "id": "M9VmjTLK_1nP"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG3Ttr8a8cbD"
      },
      "source": [
        "6. Viết hàm mất mát"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(X, y, m):\n",
        "  n = len(y)\n",
        "  y_pred = predict(X, m)\n",
        "  total_error = 0.0\n",
        "  for i in range(n):\n",
        "    total_error += (y[i]-y_pred[i])**2\n",
        "  return total_error/n"
      ],
      "metadata": {
        "id": "_g6ZxWMxAXJW"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.1. Viết hàm cập nhật tham số"
      ],
      "metadata": {
        "id": "epzAgvT8Bmp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(X, y, m, learning_rate):\n",
        "  n = len(y)\n",
        "  m_deriv = 0.0\n",
        "  y_pred = predict(X, m)\n",
        "  for i in range(n):\n",
        "    m_deriv += -2*X[i].reshape(-1,1)*(y[i]-y_pred[i])\n",
        "  m -= learning_rate*m_deriv/n\n",
        "  return m"
      ],
      "metadata": {
        "id": "is3Go-2VBxtO"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoZXvgatDFfG",
        "outputId": "9a3265cd-c19c-4f55-b441-66a17bf524b3"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 4), (100,))"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoAguvks8cbD"
      },
      "source": [
        "7. Viết hàm train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, m, learning_rate, iters):\n",
        "  loss_history = []\n",
        "  for i in range(iters):\n",
        "    m = update_weights(X, y, m, learning_rate)\n",
        "    loss = loss_function(X, y, m, learning_rate)\n",
        "    loss_history.append(loss)\n",
        "    if i % 10 == 0:\n",
        "      print(f'iter={i}, m={m}, loss={loss}')\n",
        "  return m, loss_history"
      ],
      "metadata": {
        "id": "-uHmNsteBLxX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgR6-pf8cbE"
      },
      "source": [
        "8. Sử dụng hàm train đẻ train bộ dữ liệu trên"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "iters = 3000\n",
        "m = np.zeros([X.shape[1],1])\n",
        "m, loss = train(X, y, m, learning_rate, iters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAQx338-CVzf",
        "outputId": "59b89c79-5a72-4db6-b2bb-08596d0ffd73"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter=0, m=[[0.11388189]\n",
            " [0.01788501]\n",
            " [0.06392467]\n",
            " [0.03404619]], loss=[0.20488192]\n",
            "iter=10, m=[[0.39467655]\n",
            " [0.07730012]\n",
            " [0.23924507]\n",
            " [0.11170765]], loss=[0.02764689]\n",
            "iter=20, m=[[0.39785118]\n",
            " [0.09745661]\n",
            " [0.26251358]\n",
            " [0.10432673]], loss=[0.02654439]\n",
            "iter=30, m=[[0.3907886 ]\n",
            " [0.11546156]\n",
            " [0.27813568]\n",
            " [0.09385516]], loss=[0.0258184]\n",
            "iter=40, m=[[0.38405235]\n",
            " [0.13279995]\n",
            " [0.29205425]\n",
            " [0.08358521]], loss=[0.02517486]\n",
            "iter=50, m=[[0.37797281]\n",
            " [0.14953806]\n",
            " [0.3046646 ]\n",
            " [0.07366414]], loss=[0.02460173]\n",
            "iter=60, m=[[0.37248411]\n",
            " [0.16568762]\n",
            " [0.31612088]\n",
            " [0.06410831]], loss=[0.02408949]\n",
            "iter=70, m=[[0.36751501]\n",
            " [0.18125987]\n",
            " [0.32655039]\n",
            " [0.05492436]], loss=[0.02363028]\n",
            "iter=80, m=[[0.36300307]\n",
            " [0.19626737]\n",
            " [0.33606437]\n",
            " [0.04611477]], loss=[0.02321755]\n",
            "iter=90, m=[[0.35889403]\n",
            " [0.21072371]\n",
            " [0.34476041]\n",
            " [0.03767881]], loss=[0.02284576]\n",
            "iter=100, m=[[0.35514071]\n",
            " [0.22464334]\n",
            " [0.35272425]\n",
            " [0.02961312]], loss=[0.02251021]\n",
            "iter=110, m=[[0.35170206]\n",
            " [0.23804124]\n",
            " [0.3600313 ]\n",
            " [0.02191218]], loss=[0.02220687]\n",
            "iter=120, m=[[0.34854236]\n",
            " [0.25093283]\n",
            " [0.366748  ]\n",
            " [0.01456879]], loss=[0.02193227]\n",
            "iter=130, m=[[0.34563046]\n",
            " [0.26333373]\n",
            " [0.37293293]\n",
            " [0.00757439]], loss=[0.02168339]\n",
            "iter=140, m=[[0.34293924]\n",
            " [0.27525967]\n",
            " [0.37863788]\n",
            " [0.00091939]], loss=[0.02145758]\n",
            "iter=150, m=[[ 0.34044497]\n",
            " [ 0.28672637]\n",
            " [ 0.38390864]\n",
            " [-0.00540659]], loss=[0.02125253]\n",
            "iter=160, m=[[ 0.33812697]\n",
            " [ 0.29774947]\n",
            " [ 0.38878581]\n",
            " [-0.01141448]], loss=[0.02106617]\n",
            "iter=170, m=[[ 0.33596712]\n",
            " [ 0.30834441]\n",
            " [ 0.39330547]\n",
            " [-0.01711559]], loss=[0.02089669]\n",
            "iter=180, m=[[ 0.33394956]\n",
            " [ 0.31852641]\n",
            " [ 0.39749968]\n",
            " [-0.02252146]], loss=[0.02074246]\n",
            "iter=190, m=[[ 0.33206037]\n",
            " [ 0.32831039]\n",
            " [ 0.40139701]\n",
            " [-0.02764375]], loss=[0.02060204]\n",
            "iter=200, m=[[ 0.33028735]\n",
            " [ 0.33771097]\n",
            " [ 0.40502301]\n",
            " [-0.0324941 ]], loss=[0.02047413]\n",
            "iter=210, m=[[ 0.32861973]\n",
            " [ 0.34674241]\n",
            " [ 0.40840051]\n",
            " [-0.03708408]], loss=[0.02035755]\n",
            "iter=220, m=[[ 0.32704805]\n",
            " [ 0.3554186 ]\n",
            " [ 0.41154997]\n",
            " [-0.04142509]], loss=[0.02025127]\n",
            "iter=230, m=[[ 0.32556396]\n",
            " [ 0.36375303]\n",
            " [ 0.41448981]\n",
            " [-0.04552833]], loss=[0.02015433]\n",
            "iter=240, m=[[ 0.32416006]\n",
            " [ 0.3717588 ]\n",
            " [ 0.41723659]\n",
            " [-0.04940476]], loss=[0.02006588]\n",
            "iter=250, m=[[ 0.3228298 ]\n",
            " [ 0.37944861]\n",
            " [ 0.41980525]\n",
            " [-0.05306503]], loss=[0.01998515]\n",
            "iter=260, m=[[ 0.32156736]\n",
            " [ 0.38683473]\n",
            " [ 0.4222093 ]\n",
            " [-0.0565195 ]], loss=[0.01991144]\n",
            "iter=270, m=[[ 0.32036757]\n",
            " [ 0.39392902]\n",
            " [ 0.42446099]\n",
            " [-0.05977817]], loss=[0.01984413]\n",
            "iter=280, m=[[ 0.3192258 ]\n",
            " [ 0.40074296]\n",
            " [ 0.42657143]\n",
            " [-0.06285072]], loss=[0.01978263]\n",
            "iter=290, m=[[ 0.31813791]\n",
            " [ 0.4072876 ]\n",
            " [ 0.42855076]\n",
            " [-0.06574648]], loss=[0.01972642]\n",
            "iter=300, m=[[ 0.31710021]\n",
            " [ 0.4135736 ]\n",
            " [ 0.43040818]\n",
            " [-0.06847439]], loss=[0.01967505]\n",
            "iter=310, m=[[ 0.31610935]\n",
            " [ 0.41961122]\n",
            " [ 0.43215214]\n",
            " [-0.07104308]], loss=[0.01962807]\n",
            "iter=320, m=[[ 0.31516234]\n",
            " [ 0.42541036]\n",
            " [ 0.43379036]\n",
            " [-0.07346078]], loss=[0.0195851]\n",
            "iter=330, m=[[ 0.31425644]\n",
            " [ 0.43098053]\n",
            " [ 0.43532991]\n",
            " [-0.07573539]], loss=[0.01954579]\n",
            "iter=340, m=[[ 0.3133892 ]\n",
            " [ 0.43633088]\n",
            " [ 0.43677732]\n",
            " [-0.07787446]], loss=[0.01950982]\n",
            "iter=350, m=[[ 0.31255837]\n",
            " [ 0.44147022]\n",
            " [ 0.43813857]\n",
            " [-0.07988521]], loss=[0.01947689]\n",
            "iter=360, m=[[ 0.31176191]\n",
            " [ 0.44640699]\n",
            " [ 0.43941919]\n",
            " [-0.08177451]], loss=[0.01944673]\n",
            "iter=370, m=[[ 0.31099793]\n",
            " [ 0.45114932]\n",
            " [ 0.4406243 ]\n",
            " [-0.08354892]], loss=[0.01941911]\n",
            "iter=380, m=[[ 0.31026473]\n",
            " [ 0.45570502]\n",
            " [ 0.44175862]\n",
            " [-0.0852147 ]], loss=[0.01939381]\n",
            "iter=390, m=[[ 0.30956071]\n",
            " [ 0.46008158]\n",
            " [ 0.44282656]\n",
            " [-0.08677779]], loss=[0.01937062]\n",
            "iter=400, m=[[ 0.30888442]\n",
            " [ 0.4642862 ]\n",
            " [ 0.44383217]\n",
            " [-0.08824384]], loss=[0.01934937]\n",
            "iter=410, m=[[ 0.3082345 ]\n",
            " [ 0.46832578]\n",
            " [ 0.44477924]\n",
            " [-0.08961824]], loss=[0.01932988]\n",
            "iter=420, m=[[ 0.30760971]\n",
            " [ 0.47220695]\n",
            " [ 0.4456713 ]\n",
            " [-0.09090609]], loss=[0.01931201]\n",
            "iter=430, m=[[ 0.30700887]\n",
            " [ 0.47593609]\n",
            " [ 0.44651164]\n",
            " [-0.09211225]], loss=[0.01929561]\n",
            "iter=440, m=[[ 0.30643088]\n",
            " [ 0.47951928]\n",
            " [ 0.44730333]\n",
            " [-0.09324132]], loss=[0.01928057]\n",
            "iter=450, m=[[ 0.30587474]\n",
            " [ 0.48296239]\n",
            " [ 0.44804922]\n",
            " [-0.09429766]], loss=[0.01926676]\n",
            "iter=460, m=[[ 0.30533949]\n",
            " [ 0.48627104]\n",
            " [ 0.448752  ]\n",
            " [-0.09528542]], loss=[0.01925408]\n",
            "iter=470, m=[[ 0.30482422]\n",
            " [ 0.48945062]\n",
            " [ 0.44941418]\n",
            " [-0.09620853]], loss=[0.01924244]\n",
            "iter=480, m=[[ 0.3043281 ]\n",
            " [ 0.49250629]\n",
            " [ 0.45003811]\n",
            " [-0.09707071]], loss=[0.01923174]\n",
            "iter=490, m=[[ 0.30385032]\n",
            " [ 0.49544303]\n",
            " [ 0.450626  ]\n",
            " [-0.09787547]], loss=[0.01922192]\n",
            "iter=500, m=[[ 0.30339014]\n",
            " [ 0.49826558]\n",
            " [ 0.45117991]\n",
            " [-0.09862616]], loss=[0.01921289]\n",
            "iter=510, m=[[ 0.30294683]\n",
            " [ 0.5009785 ]\n",
            " [ 0.45170179]\n",
            " [-0.09932593]], loss=[0.01920458]\n",
            "iter=520, m=[[ 0.30251972]\n",
            " [ 0.50358619]\n",
            " [ 0.45219347]\n",
            " [-0.09997778]], loss=[0.01919695]\n",
            "iter=530, m=[[ 0.30210818]\n",
            " [ 0.50609283]\n",
            " [ 0.45265665]\n",
            " [-0.10058453]], loss=[0.01918993]\n",
            "iter=540, m=[[ 0.30171158]\n",
            " [ 0.50850244]\n",
            " [ 0.45309297]\n",
            " [-0.10114885]], loss=[0.01918347]\n",
            "iter=550, m=[[ 0.30132935]\n",
            " [ 0.5108189 ]\n",
            " [ 0.45350393]\n",
            " [-0.10167327]], loss=[0.01917752]\n",
            "iter=560, m=[[ 0.30096094]\n",
            " [ 0.51304591]\n",
            " [ 0.45389097]\n",
            " [-0.10216018]], loss=[0.01917205]\n",
            "iter=570, m=[[ 0.30060581]\n",
            " [ 0.51518702]\n",
            " [ 0.45425545]\n",
            " [-0.10261185]], loss=[0.01916701]\n",
            "iter=580, m=[[ 0.30026346]\n",
            " [ 0.51724563]\n",
            " [ 0.45459863]\n",
            " [-0.1030304 ]], loss=[0.01916237]\n",
            "iter=590, m=[[ 0.29993341]\n",
            " [ 0.51922502]\n",
            " [ 0.45492171]\n",
            " [-0.10341785]], loss=[0.0191581]\n",
            "iter=600, m=[[ 0.2996152 ]\n",
            " [ 0.52112832]\n",
            " [ 0.45522582]\n",
            " [-0.1037761 ]], loss=[0.01915416]\n",
            "iter=610, m=[[ 0.29930838]\n",
            " [ 0.52295855]\n",
            " [ 0.45551204]\n",
            " [-0.10410696]], loss=[0.01915054]\n",
            "iter=620, m=[[ 0.29901253]\n",
            " [ 0.52471858]\n",
            " [ 0.45578136]\n",
            " [-0.10441211]], loss=[0.01914719]\n",
            "iter=630, m=[[ 0.29872724]\n",
            " [ 0.52641119]\n",
            " [ 0.45603474]\n",
            " [-0.10469317]], loss=[0.01914411]\n",
            "iter=640, m=[[ 0.29845214]\n",
            " [ 0.52803902]\n",
            " [ 0.45627308]\n",
            " [-0.10495163]], loss=[0.01914126]\n",
            "iter=650, m=[[ 0.29818683]\n",
            " [ 0.52960464]\n",
            " [ 0.45649722]\n",
            " [-0.10518893]], loss=[0.01913864]\n",
            "iter=660, m=[[ 0.29793097]\n",
            " [ 0.53111048]\n",
            " [ 0.45670795]\n",
            " [-0.1054064 ]], loss=[0.01913622]\n",
            "iter=670, m=[[ 0.2976842 ]\n",
            " [ 0.5325589 ]\n",
            " [ 0.45690605]\n",
            " [-0.10560532]], loss=[0.01913399]\n",
            "iter=680, m=[[ 0.2974462 ]\n",
            " [ 0.53395214]\n",
            " [ 0.45709222]\n",
            " [-0.10578689]], loss=[0.01913193]\n",
            "iter=690, m=[[ 0.29721665]\n",
            " [ 0.53529236]\n",
            " [ 0.45726713]\n",
            " [-0.10595222]], loss=[0.01913002]\n",
            "iter=700, m=[[ 0.29699525]\n",
            " [ 0.53658163]\n",
            " [ 0.45743142]\n",
            " [-0.10610237]], loss=[0.01912826]\n",
            "iter=710, m=[[ 0.29678169]\n",
            " [ 0.53782195]\n",
            " [ 0.45758569]\n",
            " [-0.10623835]], loss=[0.01912664]\n",
            "iter=720, m=[[ 0.2965757 ]\n",
            " [ 0.53901523]\n",
            " [ 0.45773052]\n",
            " [-0.1063611 ]], loss=[0.01912514]\n",
            "iter=730, m=[[ 0.29637701]\n",
            " [ 0.5401633 ]\n",
            " [ 0.45786643]\n",
            " [-0.1064715 ]], loss=[0.01912376]\n",
            "iter=740, m=[[ 0.29618534]\n",
            " [ 0.54126791]\n",
            " [ 0.45799394]\n",
            " [-0.10657039]], loss=[0.01912248]\n",
            "iter=750, m=[[ 0.29600046]\n",
            " [ 0.54233076]\n",
            " [ 0.45811353]\n",
            " [-0.10665854]], loss=[0.01912129]\n",
            "iter=760, m=[[ 0.29582211]\n",
            " [ 0.54335347]\n",
            " [ 0.45822564]\n",
            " [-0.10673671]], loss=[0.0191202]\n",
            "iter=770, m=[[ 0.29565006]\n",
            " [ 0.54433759]\n",
            " [ 0.45833071]\n",
            " [-0.10680558]], loss=[0.01911919]\n",
            "iter=780, m=[[ 0.29548409]\n",
            " [ 0.54528462]\n",
            " [ 0.45842914]\n",
            " [-0.10686581]], loss=[0.01911825]\n",
            "iter=790, m=[[ 0.29532398]\n",
            " [ 0.54619599]\n",
            " [ 0.45852131]\n",
            " [-0.10691801]], loss=[0.01911738]\n",
            "iter=800, m=[[ 0.29516952]\n",
            " [ 0.54707308]\n",
            " [ 0.45860759]\n",
            " [-0.10696276]], loss=[0.01911658]\n",
            "iter=810, m=[[ 0.2950205 ]\n",
            " [ 0.54791721]\n",
            " [ 0.45868831]\n",
            " [-0.10700059]], loss=[0.01911584]\n",
            "iter=820, m=[[ 0.29487675]\n",
            " [ 0.54872966]\n",
            " [ 0.4587638 ]\n",
            " [-0.10703203]], loss=[0.01911515]\n",
            "iter=830, m=[[ 0.29473806]\n",
            " [ 0.54951164]\n",
            " [ 0.45883436]\n",
            " [-0.10705754]], loss=[0.01911452]\n",
            "iter=840, m=[[ 0.29460426]\n",
            " [ 0.55026432]\n",
            " [ 0.45890028]\n",
            " [-0.10707757]], loss=[0.01911393]\n",
            "iter=850, m=[[ 0.29447517]\n",
            " [ 0.55098883]\n",
            " [ 0.45896184]\n",
            " [-0.10709255]], loss=[0.01911339]\n",
            "iter=860, m=[[ 0.29435063]\n",
            " [ 0.55168625]\n",
            " [ 0.45901928]\n",
            " [-0.10710286]], loss=[0.01911288]\n",
            "iter=870, m=[[ 0.29423048]\n",
            " [ 0.55235762]\n",
            " [ 0.45907285]\n",
            " [-0.10710889]], loss=[0.01911242]\n",
            "iter=880, m=[[ 0.29411455]\n",
            " [ 0.55300393]\n",
            " [ 0.45912278]\n",
            " [-0.10711097]], loss=[0.01911198]\n",
            "iter=890, m=[[ 0.2940027 ]\n",
            " [ 0.55362614]\n",
            " [ 0.45916929]\n",
            " [-0.10710943]], loss=[0.01911158]\n",
            "iter=900, m=[[ 0.29389479]\n",
            " [ 0.55422517]\n",
            " [ 0.45921258]\n",
            " [-0.10710457]], loss=[0.01911121]\n",
            "iter=910, m=[[ 0.29379068]\n",
            " [ 0.55480191]\n",
            " [ 0.45925284]\n",
            " [-0.10709668]], loss=[0.01911087]\n",
            "iter=920, m=[[ 0.29369023]\n",
            " [ 0.5553572 ]\n",
            " [ 0.45929026]\n",
            " [-0.10708603]], loss=[0.01911055]\n",
            "iter=930, m=[[ 0.2935933 ]\n",
            " [ 0.55589187]\n",
            " [ 0.459325  ]\n",
            " [-0.10707286]], loss=[0.01911025]\n",
            "iter=940, m=[[ 0.29349979]\n",
            " [ 0.55640668]\n",
            " [ 0.45935723]\n",
            " [-0.1070574 ]], loss=[0.01910998]\n",
            "iter=950, m=[[ 0.29340956]\n",
            " [ 0.55690241]\n",
            " [ 0.4593871 ]\n",
            " [-0.10703988]], loss=[0.01910972]\n",
            "iter=960, m=[[ 0.2933225 ]\n",
            " [ 0.55737977]\n",
            " [ 0.45941476]\n",
            " [-0.10702049]], loss=[0.01910948]\n",
            "iter=970, m=[[ 0.2932385 ]\n",
            " [ 0.55783946]\n",
            " [ 0.45944034]\n",
            " [-0.10699942]], loss=[0.01910927]\n",
            "iter=980, m=[[ 0.29315745]\n",
            " [ 0.55828214]\n",
            " [ 0.45946397]\n",
            " [-0.10697686]], loss=[0.01910906]\n",
            "iter=990, m=[[ 0.29307925]\n",
            " [ 0.55870846]\n",
            " [ 0.45948577]\n",
            " [-0.10695296]], loss=[0.01910887]\n",
            "iter=1000, m=[[ 0.29300379]\n",
            " [ 0.55911904]\n",
            " [ 0.45950585]\n",
            " [-0.10692788]], loss=[0.0191087]\n",
            "iter=1010, m=[[ 0.29293098]\n",
            " [ 0.55951448]\n",
            " [ 0.45952433]\n",
            " [-0.10690175]], loss=[0.01910854]\n",
            "iter=1020, m=[[ 0.29286072]\n",
            " [ 0.55989533]\n",
            " [ 0.45954131]\n",
            " [-0.10687472]], loss=[0.01910839]\n",
            "iter=1030, m=[[ 0.29279293]\n",
            " [ 0.56026215]\n",
            " [ 0.45955687]\n",
            " [-0.1068469 ]], loss=[0.01910825]\n",
            "iter=1040, m=[[ 0.29272752]\n",
            " [ 0.56061548]\n",
            " [ 0.45957112]\n",
            " [-0.10681841]], loss=[0.01910812]\n",
            "iter=1050, m=[[ 0.2926644 ]\n",
            " [ 0.56095581]\n",
            " [ 0.45958413]\n",
            " [-0.10678936]], loss=[0.01910799]\n",
            "iter=1060, m=[[ 0.2926035 ]\n",
            " [ 0.56128363]\n",
            " [ 0.45959598]\n",
            " [-0.10675983]], loss=[0.01910788]\n",
            "iter=1070, m=[[ 0.29254473]\n",
            " [ 0.56159941]\n",
            " [ 0.45960676]\n",
            " [-0.10672993]], loss=[0.01910778]\n",
            "iter=1080, m=[[ 0.29248802]\n",
            " [ 0.56190361]\n",
            " [ 0.45961653]\n",
            " [-0.10669973]], loss=[0.01910768]\n",
            "iter=1090, m=[[ 0.2924333 ]\n",
            " [ 0.56219666]\n",
            " [ 0.45962536]\n",
            " [-0.10666932]], loss=[0.01910759]\n",
            "iter=1100, m=[[ 0.2923805 ]\n",
            " [ 0.56247897]\n",
            " [ 0.45963331]\n",
            " [-0.10663876]], loss=[0.01910751]\n",
            "iter=1110, m=[[ 0.29232955]\n",
            " [ 0.56275094]\n",
            " [ 0.45964044]\n",
            " [-0.10660812]], loss=[0.01910743]\n",
            "iter=1120, m=[[ 0.29228038]\n",
            " [ 0.56301296]\n",
            " [ 0.45964681]\n",
            " [-0.10657746]], loss=[0.01910736]\n",
            "iter=1130, m=[[ 0.29223294]\n",
            " [ 0.56326541]\n",
            " [ 0.45965247]\n",
            " [-0.10654684]], loss=[0.01910729]\n",
            "iter=1140, m=[[ 0.29218715]\n",
            " [ 0.56350863]\n",
            " [ 0.45965747]\n",
            " [-0.1065163 ]], loss=[0.01910723]\n",
            "iter=1150, m=[[ 0.29214297]\n",
            " [ 0.56374298]\n",
            " [ 0.45966185]\n",
            " [-0.10648589]], loss=[0.01910717]\n",
            "iter=1160, m=[[ 0.29210034]\n",
            " [ 0.56396878]\n",
            " [ 0.45966566]\n",
            " [-0.10645565]], loss=[0.01910712]\n",
            "iter=1170, m=[[ 0.2920592 ]\n",
            " [ 0.56418634]\n",
            " [ 0.45966894]\n",
            " [-0.10642563]], loss=[0.01910707]\n",
            "iter=1180, m=[[ 0.2920195 ]\n",
            " [ 0.56439598]\n",
            " [ 0.45967173]\n",
            " [-0.10639585]], loss=[0.01910702]\n",
            "iter=1190, m=[[ 0.29198119]\n",
            " [ 0.56459799]\n",
            " [ 0.45967406]\n",
            " [-0.10636635]], loss=[0.01910698]\n",
            "iter=1200, m=[[ 0.29194422]\n",
            " [ 0.56479265]\n",
            " [ 0.45967597]\n",
            " [-0.10633716]], loss=[0.01910694]\n",
            "iter=1210, m=[[ 0.29190855]\n",
            " [ 0.56498023]\n",
            " [ 0.45967748]\n",
            " [-0.1063083 ]], loss=[0.0191069]\n",
            "iter=1220, m=[[ 0.29187412]\n",
            " [ 0.565161  ]\n",
            " [ 0.45967864]\n",
            " [-0.1062798 ]], loss=[0.01910687]\n",
            "iter=1230, m=[[ 0.2918409 ]\n",
            " [ 0.5653352 ]\n",
            " [ 0.45967947]\n",
            " [-0.10625167]], loss=[0.01910684]\n",
            "iter=1240, m=[[ 0.29180884]\n",
            " [ 0.56550309]\n",
            " [ 0.45967999]\n",
            " [-0.10622393]], loss=[0.01910681]\n",
            "iter=1250, m=[[ 0.2917779 ]\n",
            " [ 0.56566488]\n",
            " [ 0.45968022]\n",
            " [-0.1061966 ]], loss=[0.01910678]\n",
            "iter=1260, m=[[ 0.29174804]\n",
            " [ 0.56582081]\n",
            " [ 0.4596802 ]\n",
            " [-0.10616969]], loss=[0.01910675]\n",
            "iter=1270, m=[[ 0.29171923]\n",
            " [ 0.5659711 ]\n",
            " [ 0.45967995]\n",
            " [-0.10614322]], loss=[0.01910673]\n",
            "iter=1280, m=[[ 0.29169142]\n",
            " [ 0.56611594]\n",
            " [ 0.45967947]\n",
            " [-0.10611719]], loss=[0.01910671]\n",
            "iter=1290, m=[[ 0.29166459]\n",
            " [ 0.56625554]\n",
            " [ 0.4596788 ]\n",
            " [-0.10609161]], loss=[0.01910669]\n",
            "iter=1300, m=[[ 0.29163869]\n",
            " [ 0.5663901 ]\n",
            " [ 0.45967794]\n",
            " [-0.10606649]], loss=[0.01910667]\n",
            "iter=1310, m=[[ 0.2916137 ]\n",
            " [ 0.5665198 ]\n",
            " [ 0.45967693]\n",
            " [-0.10604184]], loss=[0.01910665]\n",
            "iter=1320, m=[[ 0.29158958]\n",
            " [ 0.56664481]\n",
            " [ 0.45967576]\n",
            " [-0.10601766]], loss=[0.01910663]\n",
            "iter=1330, m=[[ 0.29156631]\n",
            " [ 0.56676531]\n",
            " [ 0.45967446]\n",
            " [-0.10599395]], loss=[0.01910662]\n",
            "iter=1340, m=[[ 0.29154384]\n",
            " [ 0.56688146]\n",
            " [ 0.45967304]\n",
            " [-0.10597071]], loss=[0.0191066]\n",
            "iter=1350, m=[[ 0.29152217]\n",
            " [ 0.56699343]\n",
            " [ 0.45967151]\n",
            " [-0.10594795]], loss=[0.01910659]\n",
            "iter=1360, m=[[ 0.29150125]\n",
            " [ 0.56710136]\n",
            " [ 0.45966989]\n",
            " [-0.10592566]], loss=[0.01910657]\n",
            "iter=1370, m=[[ 0.29148106]\n",
            " [ 0.5672054 ]\n",
            " [ 0.45966817]\n",
            " [-0.10590385]], loss=[0.01910656]\n",
            "iter=1380, m=[[ 0.29146158]\n",
            " [ 0.5673057 ]\n",
            " [ 0.45966639]\n",
            " [-0.10588252]], loss=[0.01910655]\n",
            "iter=1390, m=[[ 0.29144277]\n",
            " [ 0.56740239]\n",
            " [ 0.45966454]\n",
            " [-0.10586165]], loss=[0.01910654]\n",
            "iter=1400, m=[[ 0.29142463]\n",
            " [ 0.56749561]\n",
            " [ 0.45966263]\n",
            " [-0.10584126]], loss=[0.01910653]\n",
            "iter=1410, m=[[ 0.29140711]\n",
            " [ 0.56758548]\n",
            " [ 0.45966067]\n",
            " [-0.10582132]], loss=[0.01910652]\n",
            "iter=1420, m=[[ 0.29139021]\n",
            " [ 0.56767211]\n",
            " [ 0.45965867]\n",
            " [-0.10580185]], loss=[0.01910652]\n",
            "iter=1430, m=[[ 0.2913739 ]\n",
            " [ 0.56775564]\n",
            " [ 0.45965663]\n",
            " [-0.10578284]], loss=[0.01910651]\n",
            "iter=1440, m=[[ 0.29135816]\n",
            " [ 0.56783617]\n",
            " [ 0.45965457]\n",
            " [-0.10576428]], loss=[0.0191065]\n",
            "iter=1450, m=[[ 0.29134297]\n",
            " [ 0.56791381]\n",
            " [ 0.45965248]\n",
            " [-0.10574616]], loss=[0.01910649]\n",
            "iter=1460, m=[[ 0.2913283 ]\n",
            " [ 0.56798867]\n",
            " [ 0.45965038]\n",
            " [-0.10572849]], loss=[0.01910649]\n",
            "iter=1470, m=[[ 0.29131415]\n",
            " [ 0.56806084]\n",
            " [ 0.45964826]\n",
            " [-0.10571125]], loss=[0.01910648]\n",
            "iter=1480, m=[[ 0.2913005 ]\n",
            " [ 0.56813043]\n",
            " [ 0.45964614]\n",
            " [-0.10569444]], loss=[0.01910648]\n",
            "iter=1490, m=[[ 0.29128732]\n",
            " [ 0.56819753]\n",
            " [ 0.45964402]\n",
            " [-0.10567805]], loss=[0.01910647]\n",
            "iter=1500, m=[[ 0.2912746 ]\n",
            " [ 0.56826223]\n",
            " [ 0.45964189]\n",
            " [-0.10566208]], loss=[0.01910647]\n",
            "iter=1510, m=[[ 0.29126232]\n",
            " [ 0.56832462]\n",
            " [ 0.45963978]\n",
            " [-0.10564652]], loss=[0.01910646]\n",
            "iter=1520, m=[[ 0.29125047]\n",
            " [ 0.56838477]\n",
            " [ 0.45963766]\n",
            " [-0.10563136]], loss=[0.01910646]\n",
            "iter=1530, m=[[ 0.29123903]\n",
            " [ 0.56844278]\n",
            " [ 0.45963556]\n",
            " [-0.1056166 ]], loss=[0.01910646]\n",
            "iter=1540, m=[[ 0.291228  ]\n",
            " [ 0.56849871]\n",
            " [ 0.45963348]\n",
            " [-0.10560222]], loss=[0.01910645]\n",
            "iter=1550, m=[[ 0.29121735]\n",
            " [ 0.56855264]\n",
            " [ 0.45963141]\n",
            " [-0.10558822]], loss=[0.01910645]\n",
            "iter=1560, m=[[ 0.29120707]\n",
            " [ 0.56860466]\n",
            " [ 0.45962936]\n",
            " [-0.1055746 ]], loss=[0.01910645]\n",
            "iter=1570, m=[[ 0.29119715]\n",
            " [ 0.56865481]\n",
            " [ 0.45962733]\n",
            " [-0.10556135]], loss=[0.01910644]\n",
            "iter=1580, m=[[ 0.29118757]\n",
            " [ 0.56870318]\n",
            " [ 0.45962532]\n",
            " [-0.10554845]], loss=[0.01910644]\n",
            "iter=1590, m=[[ 0.29117833]\n",
            " [ 0.56874982]\n",
            " [ 0.45962333]\n",
            " [-0.10553591]], loss=[0.01910644]\n",
            "iter=1600, m=[[ 0.29116941]\n",
            " [ 0.5687948 ]\n",
            " [ 0.45962138]\n",
            " [-0.10552371]], loss=[0.01910644]\n",
            "iter=1610, m=[[ 0.2911608 ]\n",
            " [ 0.56883818]\n",
            " [ 0.45961944]\n",
            " [-0.10551185]], loss=[0.01910643]\n",
            "iter=1620, m=[[ 0.29115249]\n",
            " [ 0.56888001]\n",
            " [ 0.45961754]\n",
            " [-0.10550031]], loss=[0.01910643]\n",
            "iter=1630, m=[[ 0.29114447]\n",
            " [ 0.56892036]\n",
            " [ 0.45961567]\n",
            " [-0.1054891 ]], loss=[0.01910643]\n",
            "iter=1640, m=[[ 0.29113673]\n",
            " [ 0.56895927]\n",
            " [ 0.45961382]\n",
            " [-0.10547821]], loss=[0.01910643]\n",
            "iter=1650, m=[[ 0.29112926]\n",
            " [ 0.56899679]\n",
            " [ 0.45961201]\n",
            " [-0.10546762]], loss=[0.01910643]\n",
            "iter=1660, m=[[ 0.29112206]\n",
            " [ 0.56903298]\n",
            " [ 0.45961022]\n",
            " [-0.10545733]], loss=[0.01910643]\n",
            "iter=1670, m=[[ 0.2911151 ]\n",
            " [ 0.56906789]\n",
            " [ 0.45960847]\n",
            " [-0.10544734]], loss=[0.01910642]\n",
            "iter=1680, m=[[ 0.29110838]\n",
            " [ 0.56910155]\n",
            " [ 0.45960675]\n",
            " [-0.10543763]], loss=[0.01910642]\n",
            "iter=1690, m=[[ 0.2911019 ]\n",
            " [ 0.56913402]\n",
            " [ 0.45960506]\n",
            " [-0.1054282 ]], loss=[0.01910642]\n",
            "iter=1700, m=[[ 0.29109564]\n",
            " [ 0.56916534]\n",
            " [ 0.45960341]\n",
            " [-0.10541905]], loss=[0.01910642]\n",
            "iter=1710, m=[[ 0.29108961]\n",
            " [ 0.56919555]\n",
            " [ 0.45960179]\n",
            " [-0.10541016]], loss=[0.01910642]\n",
            "iter=1720, m=[[ 0.29108378]\n",
            " [ 0.56922468]\n",
            " [ 0.4596002 ]\n",
            " [-0.10540153]], loss=[0.01910642]\n",
            "iter=1730, m=[[ 0.29107816]\n",
            " [ 0.56925278]\n",
            " [ 0.45959864]\n",
            " [-0.10539315]], loss=[0.01910642]\n",
            "iter=1740, m=[[ 0.29107273]\n",
            " [ 0.56927989]\n",
            " [ 0.45959712]\n",
            " [-0.10538502]], loss=[0.01910642]\n",
            "iter=1750, m=[[ 0.29106749]\n",
            " [ 0.56930603]\n",
            " [ 0.45959563]\n",
            " [-0.10537713]], loss=[0.01910642]\n",
            "iter=1760, m=[[ 0.29106243]\n",
            " [ 0.56933125]\n",
            " [ 0.45959417]\n",
            " [-0.10536948]], loss=[0.01910642]\n",
            "iter=1770, m=[[ 0.29105755]\n",
            " [ 0.56935557]\n",
            " [ 0.45959275]\n",
            " [-0.10536205]], loss=[0.01910641]\n",
            "iter=1780, m=[[ 0.29105284]\n",
            " [ 0.56937903]\n",
            " [ 0.45959136]\n",
            " [-0.10535484]], loss=[0.01910641]\n",
            "iter=1790, m=[[ 0.29104829]\n",
            " [ 0.56940167]\n",
            " [ 0.45959   ]\n",
            " [-0.10534785]], loss=[0.01910641]\n",
            "iter=1800, m=[[ 0.2910439 ]\n",
            " [ 0.5694235 ]\n",
            " [ 0.45958867]\n",
            " [-0.10534107]], loss=[0.01910641]\n",
            "iter=1810, m=[[ 0.29103967]\n",
            " [ 0.56944456]\n",
            " [ 0.45958737]\n",
            " [-0.10533449]], loss=[0.01910641]\n",
            "iter=1820, m=[[ 0.29103558]\n",
            " [ 0.56946487]\n",
            " [ 0.4595861 ]\n",
            " [-0.10532812]], loss=[0.01910641]\n",
            "iter=1830, m=[[ 0.29103163]\n",
            " [ 0.56948447]\n",
            " [ 0.45958487]\n",
            " [-0.10532193]], loss=[0.01910641]\n",
            "iter=1840, m=[[ 0.29102783]\n",
            " [ 0.56950337]\n",
            " [ 0.45958366]\n",
            " [-0.10531594]], loss=[0.01910641]\n",
            "iter=1850, m=[[ 0.29102415]\n",
            " [ 0.5695216 ]\n",
            " [ 0.45958249]\n",
            " [-0.10531013]], loss=[0.01910641]\n",
            "iter=1860, m=[[ 0.2910206 ]\n",
            " [ 0.5695392 ]\n",
            " [ 0.45958134]\n",
            " [-0.10530449]], loss=[0.01910641]\n",
            "iter=1870, m=[[ 0.29101718]\n",
            " [ 0.56955617]\n",
            " [ 0.45958023]\n",
            " [-0.10529903]], loss=[0.01910641]\n",
            "iter=1880, m=[[ 0.29101387]\n",
            " [ 0.56957254]\n",
            " [ 0.45957914]\n",
            " [-0.10529374]], loss=[0.01910641]\n",
            "iter=1890, m=[[ 0.29101068]\n",
            " [ 0.56958833]\n",
            " [ 0.45957808]\n",
            " [-0.10528861]], loss=[0.01910641]\n",
            "iter=1900, m=[[ 0.2910076 ]\n",
            " [ 0.56960356]\n",
            " [ 0.45957704]\n",
            " [-0.10528364]], loss=[0.01910641]\n",
            "iter=1910, m=[[ 0.29100463]\n",
            " [ 0.56961826]\n",
            " [ 0.45957604]\n",
            " [-0.10527882]], loss=[0.01910641]\n",
            "iter=1920, m=[[ 0.29100176]\n",
            " [ 0.56963244]\n",
            " [ 0.45957506]\n",
            " [-0.10527415]], loss=[0.01910641]\n",
            "iter=1930, m=[[ 0.29099899]\n",
            " [ 0.56964612]\n",
            " [ 0.45957411]\n",
            " [-0.10526963]], loss=[0.01910641]\n",
            "iter=1940, m=[[ 0.29099632]\n",
            " [ 0.56965932]\n",
            " [ 0.45957318]\n",
            " [-0.10526525]], loss=[0.01910641]\n",
            "iter=1950, m=[[ 0.29099374]\n",
            " [ 0.56967205]\n",
            " [ 0.45957228]\n",
            " [-0.10526101]], loss=[0.01910641]\n",
            "iter=1960, m=[[ 0.29099125]\n",
            " [ 0.56968433]\n",
            " [ 0.4595714 ]\n",
            " [-0.10525689]], loss=[0.01910641]\n",
            "iter=1970, m=[[ 0.29098885]\n",
            " [ 0.56969618]\n",
            " [ 0.45957055]\n",
            " [-0.10525291]], loss=[0.01910641]\n",
            "iter=1980, m=[[ 0.29098653]\n",
            " [ 0.56970761]\n",
            " [ 0.45956972]\n",
            " [-0.10524906]], loss=[0.01910641]\n",
            "iter=1990, m=[[ 0.29098429]\n",
            " [ 0.56971864]\n",
            " [ 0.45956891]\n",
            " [-0.10524532]], loss=[0.01910641]\n",
            "iter=2000, m=[[ 0.29098213]\n",
            " [ 0.56972928]\n",
            " [ 0.45956812]\n",
            " [-0.10524171]], loss=[0.01910641]\n",
            "iter=2010, m=[[ 0.29098005]\n",
            " [ 0.56973955]\n",
            " [ 0.45956736]\n",
            " [-0.1052382 ]], loss=[0.01910641]\n",
            "iter=2020, m=[[ 0.29097803]\n",
            " [ 0.56974946]\n",
            " [ 0.45956662]\n",
            " [-0.10523481]], loss=[0.01910641]\n",
            "iter=2030, m=[[ 0.29097609]\n",
            " [ 0.56975902]\n",
            " [ 0.4595659 ]\n",
            " [-0.10523153]], loss=[0.01910641]\n",
            "iter=2040, m=[[ 0.29097422]\n",
            " [ 0.56976824]\n",
            " [ 0.4595652 ]\n",
            " [-0.10522835]], loss=[0.01910641]\n",
            "iter=2050, m=[[ 0.29097241]\n",
            " [ 0.56977713]\n",
            " [ 0.45956452]\n",
            " [-0.10522527]], loss=[0.01910641]\n",
            "iter=2060, m=[[ 0.29097066]\n",
            " [ 0.56978572]\n",
            " [ 0.45956386]\n",
            " [-0.1052223 ]], loss=[0.01910641]\n",
            "iter=2070, m=[[ 0.29096897]\n",
            " [ 0.569794  ]\n",
            " [ 0.45956322]\n",
            " [-0.10521941]], loss=[0.01910641]\n",
            "iter=2080, m=[[ 0.29096734]\n",
            " [ 0.56980199]\n",
            " [ 0.4595626 ]\n",
            " [-0.10521662]], loss=[0.01910641]\n",
            "iter=2090, m=[[ 0.29096577]\n",
            " [ 0.5698097 ]\n",
            " [ 0.45956199]\n",
            " [-0.10521392]], loss=[0.01910641]\n",
            "iter=2100, m=[[ 0.29096426]\n",
            " [ 0.56981714]\n",
            " [ 0.45956141]\n",
            " [-0.10521131]], loss=[0.01910641]\n",
            "iter=2110, m=[[ 0.29096279]\n",
            " [ 0.56982432]\n",
            " [ 0.45956084]\n",
            " [-0.10520877]], loss=[0.01910641]\n",
            "iter=2120, m=[[ 0.29096138]\n",
            " [ 0.56983124]\n",
            " [ 0.45956028]\n",
            " [-0.10520633]], loss=[0.01910641]\n",
            "iter=2130, m=[[ 0.29096002]\n",
            " [ 0.56983793]\n",
            " [ 0.45955975]\n",
            " [-0.10520396]], loss=[0.01910641]\n",
            "iter=2140, m=[[ 0.2909587 ]\n",
            " [ 0.56984437]\n",
            " [ 0.45955923]\n",
            " [-0.10520166]], loss=[0.01910641]\n",
            "iter=2150, m=[[ 0.29095743]\n",
            " [ 0.56985059]\n",
            " [ 0.45955872]\n",
            " [-0.10519944]], loss=[0.01910641]\n",
            "iter=2160, m=[[ 0.2909562 ]\n",
            " [ 0.5698566 ]\n",
            " [ 0.45955823]\n",
            " [-0.1051973 ]], loss=[0.01910641]\n",
            "iter=2170, m=[[ 0.29095502]\n",
            " [ 0.56986239]\n",
            " [ 0.45955776]\n",
            " [-0.10519522]], loss=[0.01910641]\n",
            "iter=2180, m=[[ 0.29095388]\n",
            " [ 0.56986798]\n",
            " [ 0.4595573 ]\n",
            " [-0.10519321]], loss=[0.01910641]\n",
            "iter=2190, m=[[ 0.29095278]\n",
            " [ 0.56987337]\n",
            " [ 0.45955685]\n",
            " [-0.10519127]], loss=[0.01910641]\n",
            "iter=2200, m=[[ 0.29095171]\n",
            " [ 0.56987858]\n",
            " [ 0.45955642]\n",
            " [-0.10518939]], loss=[0.01910641]\n",
            "iter=2210, m=[[ 0.29095068]\n",
            " [ 0.5698836 ]\n",
            " [ 0.459556  ]\n",
            " [-0.10518757]], loss=[0.01910641]\n",
            "iter=2220, m=[[ 0.29094969]\n",
            " [ 0.56988844]\n",
            " [ 0.45955559]\n",
            " [-0.10518581]], loss=[0.01910641]\n",
            "iter=2230, m=[[ 0.29094874]\n",
            " [ 0.56989312]\n",
            " [ 0.4595552 ]\n",
            " [-0.1051841 ]], loss=[0.01910641]\n",
            "iter=2240, m=[[ 0.29094781]\n",
            " [ 0.56989763]\n",
            " [ 0.45955481]\n",
            " [-0.10518246]], loss=[0.01910641]\n",
            "iter=2250, m=[[ 0.29094692]\n",
            " [ 0.56990199]\n",
            " [ 0.45955444]\n",
            " [-0.10518086]], loss=[0.01910641]\n",
            "iter=2260, m=[[ 0.29094606]\n",
            " [ 0.56990619]\n",
            " [ 0.45955408]\n",
            " [-0.10517932]], loss=[0.01910641]\n",
            "iter=2270, m=[[ 0.29094523]\n",
            " [ 0.56991024]\n",
            " [ 0.45955374]\n",
            " [-0.10517783]], loss=[0.01910641]\n",
            "iter=2280, m=[[ 0.29094443]\n",
            " [ 0.56991415]\n",
            " [ 0.4595534 ]\n",
            " [-0.10517639]], loss=[0.01910641]\n",
            "iter=2290, m=[[ 0.29094365]\n",
            " [ 0.56991793]\n",
            " [ 0.45955307]\n",
            " [-0.105175  ]], loss=[0.01910641]\n",
            "iter=2300, m=[[ 0.2909429 ]\n",
            " [ 0.56992157]\n",
            " [ 0.45955275]\n",
            " [-0.10517365]], loss=[0.01910641]\n",
            "iter=2310, m=[[ 0.29094218]\n",
            " [ 0.56992508]\n",
            " [ 0.45955245]\n",
            " [-0.10517235]], loss=[0.01910641]\n",
            "iter=2320, m=[[ 0.29094149]\n",
            " [ 0.56992848]\n",
            " [ 0.45955215]\n",
            " [-0.10517109]], loss=[0.01910641]\n",
            "iter=2330, m=[[ 0.29094082]\n",
            " [ 0.56993175]\n",
            " [ 0.45955186]\n",
            " [-0.10516987]], loss=[0.01910641]\n",
            "iter=2340, m=[[ 0.29094017]\n",
            " [ 0.56993491]\n",
            " [ 0.45955158]\n",
            " [-0.10516869]], loss=[0.01910641]\n",
            "iter=2350, m=[[ 0.29093954]\n",
            " [ 0.56993796]\n",
            " [ 0.45955131]\n",
            " [-0.10516755]], loss=[0.01910641]\n",
            "iter=2360, m=[[ 0.29093894]\n",
            " [ 0.5699409 ]\n",
            " [ 0.45955105]\n",
            " [-0.10516645]], loss=[0.01910641]\n",
            "iter=2370, m=[[ 0.29093835]\n",
            " [ 0.56994374]\n",
            " [ 0.4595508 ]\n",
            " [-0.10516539]], loss=[0.01910641]\n",
            "iter=2380, m=[[ 0.29093779]\n",
            " [ 0.56994647]\n",
            " [ 0.45955055]\n",
            " [-0.10516436]], loss=[0.01910641]\n",
            "iter=2390, m=[[ 0.29093725]\n",
            " [ 0.56994912]\n",
            " [ 0.45955031]\n",
            " [-0.10516336]], loss=[0.01910641]\n",
            "iter=2400, m=[[ 0.29093672]\n",
            " [ 0.56995167]\n",
            " [ 0.45955008]\n",
            " [-0.1051624 ]], loss=[0.01910641]\n",
            "iter=2410, m=[[ 0.29093622]\n",
            " [ 0.56995413]\n",
            " [ 0.45954986]\n",
            " [-0.10516147]], loss=[0.01910641]\n",
            "iter=2420, m=[[ 0.29093573]\n",
            " [ 0.56995651]\n",
            " [ 0.45954965]\n",
            " [-0.10516057]], loss=[0.01910641]\n",
            "iter=2430, m=[[ 0.29093526]\n",
            " [ 0.5699588 ]\n",
            " [ 0.45954944]\n",
            " [-0.1051597 ]], loss=[0.01910641]\n",
            "iter=2440, m=[[ 0.2909348 ]\n",
            " [ 0.56996101]\n",
            " [ 0.45954924]\n",
            " [-0.10515886]], loss=[0.01910641]\n",
            "iter=2450, m=[[ 0.29093436]\n",
            " [ 0.56996315]\n",
            " [ 0.45954904]\n",
            " [-0.10515805]], loss=[0.01910641]\n",
            "iter=2460, m=[[ 0.29093394]\n",
            " [ 0.56996521]\n",
            " [ 0.45954885]\n",
            " [-0.10515726]], loss=[0.01910641]\n",
            "iter=2470, m=[[ 0.29093353]\n",
            " [ 0.5699672 ]\n",
            " [ 0.45954867]\n",
            " [-0.1051565 ]], loss=[0.01910641]\n",
            "iter=2480, m=[[ 0.29093313]\n",
            " [ 0.56996911]\n",
            " [ 0.45954849]\n",
            " [-0.10515577]], loss=[0.01910641]\n",
            "iter=2490, m=[[ 0.29093275]\n",
            " [ 0.56997097]\n",
            " [ 0.45954832]\n",
            " [-0.10515506]], loss=[0.01910641]\n",
            "iter=2500, m=[[ 0.29093238]\n",
            " [ 0.56997275]\n",
            " [ 0.45954815]\n",
            " [-0.10515437]], loss=[0.01910641]\n",
            "iter=2510, m=[[ 0.29093203]\n",
            " [ 0.56997448]\n",
            " [ 0.45954799]\n",
            " [-0.10515371]], loss=[0.01910641]\n",
            "iter=2520, m=[[ 0.29093168]\n",
            " [ 0.56997614]\n",
            " [ 0.45954784]\n",
            " [-0.10515307]], loss=[0.01910641]\n",
            "iter=2530, m=[[ 0.29093135]\n",
            " [ 0.56997775]\n",
            " [ 0.45954769]\n",
            " [-0.10515245]], loss=[0.01910641]\n",
            "iter=2540, m=[[ 0.29093103]\n",
            " [ 0.5699793 ]\n",
            " [ 0.45954754]\n",
            " [-0.10515185]], loss=[0.01910641]\n",
            "iter=2550, m=[[ 0.29093072]\n",
            " [ 0.56998079]\n",
            " [ 0.4595474 ]\n",
            " [-0.10515128]], loss=[0.01910641]\n",
            "iter=2560, m=[[ 0.29093043]\n",
            " [ 0.56998224]\n",
            " [ 0.45954726]\n",
            " [-0.10515072]], loss=[0.01910641]\n",
            "iter=2570, m=[[ 0.29093014]\n",
            " [ 0.56998363]\n",
            " [ 0.45954713]\n",
            " [-0.10515018]], loss=[0.01910641]\n",
            "iter=2580, m=[[ 0.29092986]\n",
            " [ 0.56998498]\n",
            " [ 0.459547  ]\n",
            " [-0.10514966]], loss=[0.01910641]\n",
            "iter=2590, m=[[ 0.29092959]\n",
            " [ 0.56998627]\n",
            " [ 0.45954688]\n",
            " [-0.10514915]], loss=[0.01910641]\n",
            "iter=2600, m=[[ 0.29092934]\n",
            " [ 0.56998753]\n",
            " [ 0.45954676]\n",
            " [-0.10514867]], loss=[0.01910641]\n",
            "iter=2610, m=[[ 0.29092909]\n",
            " [ 0.56998874]\n",
            " [ 0.45954665]\n",
            " [-0.1051482 ]], loss=[0.01910641]\n",
            "iter=2620, m=[[ 0.29092884]\n",
            " [ 0.5699899 ]\n",
            " [ 0.45954653]\n",
            " [-0.10514774]], loss=[0.01910641]\n",
            "iter=2630, m=[[ 0.29092861]\n",
            " [ 0.56999103]\n",
            " [ 0.45954643]\n",
            " [-0.1051473 ]], loss=[0.01910641]\n",
            "iter=2640, m=[[ 0.29092839]\n",
            " [ 0.56999212]\n",
            " [ 0.45954632]\n",
            " [-0.10514688]], loss=[0.01910641]\n",
            "iter=2650, m=[[ 0.29092817]\n",
            " [ 0.56999316]\n",
            " [ 0.45954622]\n",
            " [-0.10514647]], loss=[0.01910641]\n",
            "iter=2660, m=[[ 0.29092796]\n",
            " [ 0.56999418]\n",
            " [ 0.45954612]\n",
            " [-0.10514607]], loss=[0.01910641]\n",
            "iter=2670, m=[[ 0.29092776]\n",
            " [ 0.56999515]\n",
            " [ 0.45954603]\n",
            " [-0.10514569]], loss=[0.01910641]\n",
            "iter=2680, m=[[ 0.29092757]\n",
            " [ 0.5699961 ]\n",
            " [ 0.45954594]\n",
            " [-0.10514532]], loss=[0.01910641]\n",
            "iter=2690, m=[[ 0.29092738]\n",
            " [ 0.56999701]\n",
            " [ 0.45954585]\n",
            " [-0.10514496]], loss=[0.01910641]\n",
            "iter=2700, m=[[ 0.2909272 ]\n",
            " [ 0.56999788]\n",
            " [ 0.45954576]\n",
            " [-0.10514461]], loss=[0.01910641]\n",
            "iter=2710, m=[[ 0.29092702]\n",
            " [ 0.56999873]\n",
            " [ 0.45954568]\n",
            " [-0.10514428]], loss=[0.01910641]\n",
            "iter=2720, m=[[ 0.29092685]\n",
            " [ 0.56999955]\n",
            " [ 0.4595456 ]\n",
            " [-0.10514396]], loss=[0.01910641]\n",
            "iter=2730, m=[[ 0.29092669]\n",
            " [ 0.57000034]\n",
            " [ 0.45954552]\n",
            " [-0.10514365]], loss=[0.01910641]\n",
            "iter=2740, m=[[ 0.29092653]\n",
            " [ 0.5700011 ]\n",
            " [ 0.45954545]\n",
            " [-0.10514335]], loss=[0.01910641]\n",
            "iter=2750, m=[[ 0.29092638]\n",
            " [ 0.57000184]\n",
            " [ 0.45954538]\n",
            " [-0.10514305]], loss=[0.01910641]\n",
            "iter=2760, m=[[ 0.29092623]\n",
            " [ 0.57000255]\n",
            " [ 0.45954531]\n",
            " [-0.10514277]], loss=[0.01910641]\n",
            "iter=2770, m=[[ 0.29092609]\n",
            " [ 0.57000323]\n",
            " [ 0.45954524]\n",
            " [-0.1051425 ]], loss=[0.01910641]\n",
            "iter=2780, m=[[ 0.29092595]\n",
            " [ 0.57000389]\n",
            " [ 0.45954517]\n",
            " [-0.10514224]], loss=[0.01910641]\n",
            "iter=2790, m=[[ 0.29092582]\n",
            " [ 0.57000453]\n",
            " [ 0.45954511]\n",
            " [-0.10514199]], loss=[0.01910641]\n",
            "iter=2800, m=[[ 0.29092569]\n",
            " [ 0.57000515]\n",
            " [ 0.45954505]\n",
            " [-0.10514174]], loss=[0.01910641]\n",
            "iter=2810, m=[[ 0.29092557]\n",
            " [ 0.57000574]\n",
            " [ 0.45954499]\n",
            " [-0.10514151]], loss=[0.01910641]\n",
            "iter=2820, m=[[ 0.29092545]\n",
            " [ 0.57000631]\n",
            " [ 0.45954493]\n",
            " [-0.10514128]], loss=[0.01910641]\n",
            "iter=2830, m=[[ 0.29092534]\n",
            " [ 0.57000687]\n",
            " [ 0.45954488]\n",
            " [-0.10514106]], loss=[0.01910641]\n",
            "iter=2840, m=[[ 0.29092523]\n",
            " [ 0.5700074 ]\n",
            " [ 0.45954483]\n",
            " [-0.10514084]], loss=[0.01910641]\n",
            "iter=2850, m=[[ 0.29092512]\n",
            " [ 0.57000792]\n",
            " [ 0.45954477]\n",
            " [-0.10514064]], loss=[0.01910641]\n",
            "iter=2860, m=[[ 0.29092502]\n",
            " [ 0.57000842]\n",
            " [ 0.45954472]\n",
            " [-0.10514044]], loss=[0.01910641]\n",
            "iter=2870, m=[[ 0.29092492]\n",
            " [ 0.5700089 ]\n",
            " [ 0.45954468]\n",
            " [-0.10514025]], loss=[0.01910641]\n",
            "iter=2880, m=[[ 0.29092482]\n",
            " [ 0.57000936]\n",
            " [ 0.45954463]\n",
            " [-0.10514006]], loss=[0.01910641]\n",
            "iter=2890, m=[[ 0.29092473]\n",
            " [ 0.57000981]\n",
            " [ 0.45954458]\n",
            " [-0.10513988]], loss=[0.01910641]\n",
            "iter=2900, m=[[ 0.29092464]\n",
            " [ 0.57001024]\n",
            " [ 0.45954454]\n",
            " [-0.10513971]], loss=[0.01910641]\n",
            "iter=2910, m=[[ 0.29092455]\n",
            " [ 0.57001066]\n",
            " [ 0.4595445 ]\n",
            " [-0.10513954]], loss=[0.01910641]\n",
            "iter=2920, m=[[ 0.29092447]\n",
            " [ 0.57001106]\n",
            " [ 0.45954446]\n",
            " [-0.10513938]], loss=[0.01910641]\n",
            "iter=2930, m=[[ 0.29092439]\n",
            " [ 0.57001145]\n",
            " [ 0.45954442]\n",
            " [-0.10513923]], loss=[0.01910641]\n",
            "iter=2940, m=[[ 0.29092431]\n",
            " [ 0.57001182]\n",
            " [ 0.45954438]\n",
            " [-0.10513907]], loss=[0.01910641]\n",
            "iter=2950, m=[[ 0.29092424]\n",
            " [ 0.57001218]\n",
            " [ 0.45954435]\n",
            " [-0.10513893]], loss=[0.01910641]\n",
            "iter=2960, m=[[ 0.29092416]\n",
            " [ 0.57001253]\n",
            " [ 0.45954431]\n",
            " [-0.10513879]], loss=[0.01910641]\n",
            "iter=2970, m=[[ 0.29092409]\n",
            " [ 0.57001287]\n",
            " [ 0.45954428]\n",
            " [-0.10513865]], loss=[0.01910641]\n",
            "iter=2980, m=[[ 0.29092403]\n",
            " [ 0.57001319]\n",
            " [ 0.45954424]\n",
            " [-0.10513852]], loss=[0.01910641]\n",
            "iter=2990, m=[[ 0.29092396]\n",
            " [ 0.57001351]\n",
            " [ 0.45954421]\n",
            " [-0.1051384 ]], loss=[0.01910641]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgsIVd5A8cbE"
      },
      "source": [
        "9. Vẽ biểu độ biểu thị sự giảm giá trị của hàm mất mát trong quá trình train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(range(len(loss)), loss);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "7zi5XugYEbOW",
        "outputId": "db405060-4d72-442a-cfda-dd4212079fb8"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raBEn8Rk8cbE"
      },
      "source": [
        "10. Lọc ra 10 dòng dữ liệu đầu tiên. Sử dụng tham số đã train để tìm kết quả, so sanh kết qua với y thực"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "1ItIqBk08cbF",
        "outputId": "498f4bcc-66ae-4a82-d6a9-6757ebc9c454"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          y    y_pred\n",
              "0  0.870079  0.685298\n",
              "1  0.409449  0.634327\n",
              "2  0.366142  0.660346\n",
              "3  0.728346  0.690709\n",
              "4  0.507874  0.421968\n",
              "5  0.283465  0.678895\n",
              "6  0.464567  0.600125\n",
              "7  0.519685  0.518225\n",
              "8  0.188976  0.313494\n",
              "9  0.417323  0.858483"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0e393e4-6c96-460b-9ff5-05bcf71bce3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.870079</td>\n",
              "      <td>0.685298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.409449</td>\n",
              "      <td>0.634327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.366142</td>\n",
              "      <td>0.660346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.728346</td>\n",
              "      <td>0.690709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.507874</td>\n",
              "      <td>0.421968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.283465</td>\n",
              "      <td>0.678895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.464567</td>\n",
              "      <td>0.600125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.519685</td>\n",
              "      <td>0.518225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.188976</td>\n",
              "      <td>0.313494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.417323</td>\n",
              "      <td>0.858483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0e393e4-6c96-460b-9ff5-05bcf71bce3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0e393e4-6c96-460b-9ff5-05bcf71bce3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0e393e4-6c96-460b-9ff5-05bcf71bce3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a00c7966-0267-46d8-918f-e6e8e52bda8d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a00c7966-0267-46d8-918f-e6e8e52bda8d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a00c7966-0267-46d8-918f-e6e8e52bda8d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "res",
              "summary": "{\n  \"name\": \"res\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20223731941835882,\n        \"min\": 0.1889763779527559,\n        \"max\": 1.0,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          0.3779527559055118,\n          0.8700787401574804,\n          0.610236220472441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14697064854964884,\n        \"min\": 0.28780756480816916,\n        \"max\": 1.0796087114644735,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.7024815006402512,\n          0.7505175061683204,\n          0.6321716015711625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "y_pred = predict(X, m)\n",
        "res = pd.DataFrame(np.hstack([y.reshape(-1,1), y_pred]))\n",
        "res.columns = ['y', 'y_pred']\n",
        "res.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsfNyKNEQsrd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}